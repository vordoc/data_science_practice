"""Списки и стеки имеют широкое применение, в том числе в области обработки
естественного языка (NLP, Natural Language Processing). Например, они используются для извлечения
из текста именных групп (noun chunk).

Такая группа состоит из существительного и зависимых слов
(то есть всех слов слева от существительного, которые синтаксически от него зависят, например прилагательных
или артиклей в английском языке).

Таким образом, чтобы извлечь из текста
все именные группы, нужно найти в нем все существительные с зависимыми
словами, располагающимися слева от существительного. Это можно сделать
с помощью алгоритма на основе стека"""


"""Импортируем библиотеку spacy"""
import spacy

# текст который необходимо разобрать
txt = 'List is a ubiquitous data structure in the Python programming language.'

# загружаем модель для английского языка
nlp = spacy.load('en_core_web_sm')

doc = nlp(txt)

stk = []

for word in doc:
	# Если мы нашли существительное или один из дочерних элементов, расположенных слева от этого существительного,
	# отправляем слово в стек с помощью метода append()
	if word.pos_ == 'NOUN' or word.pos_ == 'PROPN':
		stk.append(word.text)
	elif (word.head.pos_ == 'NOUN' or word.head.pos_ == 'PROPN') and (word in word.head.lefts):
		stk.append(word.text)
	# определяем, что следующее слово в тексте не является частью именной
	# группы (ни существительным, ни дочерним словом слева от него), а значит,
	# полученная группа полная, и мы извлекаем ее из стека
	elif stk:
		chunk = ''
		while stk:
			chunk = stk.pop() + ' ' + chunk
		print(chunk.strip())


